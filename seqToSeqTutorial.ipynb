{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "[u'nous y allons tous .', u'we re all going .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 38s (- 95m 26s) (500 0%) 3.7587\n",
      "1m 13s (- 90m 51s) (1000 1%) 3.3685\n",
      "1m 47s (- 87m 30s) (1500 2%) 3.0547\n",
      "2m 22s (- 86m 49s) (2000 2%) 2.8435\n",
      "2m 56s (- 85m 16s) (2500 3%) 2.8153\n",
      "3m 30s (- 84m 0s) (3000 4%) 2.6900\n",
      "4m 3s (- 82m 57s) (3500 4%) 2.6161\n",
      "4m 44s (- 84m 14s) (4000 5%) 2.7043\n",
      "5m 22s (- 84m 7s) (4500 6%) 2.6022\n",
      "5m 58s (- 83m 44s) (5000 6%) 2.5443\n",
      "6m 38s (- 83m 51s) (5500 7%) 2.5416\n",
      "7m 16s (- 83m 41s) (6000 8%) 2.4576\n",
      "7m 59s (- 84m 10s) (6500 8%) 2.4350\n",
      "8m 35s (- 83m 32s) (7000 9%) 2.4809\n",
      "9m 13s (- 83m 2s) (7500 10%) 2.3358\n",
      "9m 51s (- 82m 33s) (8000 10%) 2.3307\n",
      "10m 28s (- 81m 54s) (8500 11%) 2.2620\n",
      "11m 8s (- 81m 45s) (9000 12%) 2.2785\n",
      "11m 48s (- 81m 27s) (9500 12%) 2.3138\n",
      "12m 27s (- 80m 58s) (10000 13%) 2.2860\n",
      "13m 10s (- 80m 56s) (10500 14%) 2.2687\n",
      "13m 51s (- 80m 36s) (11000 14%) 2.0730\n",
      "14m 31s (- 80m 11s) (11500 15%) 2.1011\n",
      "15m 9s (- 79m 33s) (12000 16%) 2.0425\n",
      "15m 47s (- 78m 58s) (12500 16%) 2.0189\n",
      "16m 24s (- 78m 15s) (13000 17%) 1.9246\n",
      "17m 1s (- 77m 33s) (13500 18%) 2.0774\n",
      "17m 40s (- 77m 0s) (14000 18%) 1.9567\n",
      "18m 19s (- 76m 26s) (14500 19%) 1.9528\n",
      "18m 57s (- 75m 49s) (15000 20%) 1.9561\n",
      "19m 35s (- 75m 11s) (15500 20%) 1.9594\n",
      "20m 12s (- 74m 30s) (16000 21%) 1.8274\n",
      "20m 47s (- 73m 42s) (16500 22%) 1.8401\n",
      "21m 27s (- 73m 13s) (17000 22%) 1.8643\n",
      "22m 7s (- 72m 43s) (17500 23%) 1.8533\n",
      "22m 48s (- 72m 12s) (18000 24%) 1.7364\n",
      "23m 22s (- 71m 23s) (18500 24%) 1.8018\n",
      "23m 57s (- 70m 37s) (19000 25%) 1.6754\n",
      "24m 33s (- 69m 53s) (19500 26%) 1.6924\n",
      "25m 11s (- 69m 15s) (20000 26%) 1.7764\n",
      "25m 47s (- 68m 34s) (20500 27%) 1.6793\n",
      "26m 24s (- 67m 55s) (21000 28%) 1.6562\n",
      "27m 1s (- 67m 15s) (21500 28%) 1.8033\n",
      "27m 37s (- 66m 33s) (22000 29%) 1.6091\n",
      "28m 15s (- 65m 56s) (22500 30%) 1.5664\n",
      "28m 52s (- 65m 17s) (23000 30%) 1.6809\n",
      "29m 29s (- 64m 37s) (23500 31%) 1.5900\n",
      "30m 7s (- 64m 1s) (24000 32%) 1.5384\n",
      "30m 45s (- 63m 24s) (24500 32%) 1.5534\n",
      "31m 27s (- 62m 54s) (25000 33%) 1.5646\n",
      "32m 5s (- 62m 16s) (25500 34%) 1.5097\n",
      "32m 40s (- 61m 35s) (26000 34%) 1.4432\n",
      "33m 18s (- 60m 56s) (26500 35%) 1.5134\n",
      "33m 53s (- 60m 15s) (27000 36%) 1.4070\n",
      "34m 31s (- 59m 38s) (27500 36%) 1.4518\n",
      "35m 7s (- 58m 58s) (28000 37%) 1.3954\n",
      "35m 43s (- 58m 17s) (28500 38%) 1.4431\n",
      "36m 19s (- 57m 37s) (29000 38%) 1.3334\n",
      "36m 54s (- 56m 55s) (29500 39%) 1.4272\n",
      "37m 28s (- 56m 12s) (30000 40%) 1.2682\n",
      "38m 2s (- 55m 30s) (30500 40%) 1.3624\n",
      "38m 36s (- 54m 48s) (31000 41%) 1.3793\n",
      "39m 11s (- 54m 6s) (31500 42%) 1.3266\n",
      "39m 46s (- 53m 26s) (32000 42%) 1.2243\n",
      "40m 20s (- 52m 45s) (32500 43%) 1.3330\n",
      "40m 54s (- 52m 3s) (33000 44%) 1.2898\n",
      "41m 28s (- 51m 22s) (33500 44%) 1.2558\n",
      "42m 2s (- 50m 42s) (34000 45%) 1.3705\n",
      "42m 37s (- 50m 1s) (34500 46%) 1.2240\n",
      "43m 11s (- 49m 21s) (35000 46%) 1.2252\n",
      "43m 45s (- 48m 41s) (35500 47%) 1.1655\n",
      "44m 19s (- 48m 1s) (36000 48%) 1.1196\n",
      "44m 53s (- 47m 21s) (36500 48%) 1.1693\n",
      "45m 28s (- 46m 42s) (37000 49%) 1.1448\n",
      "46m 6s (- 46m 6s) (37500 50%) 1.0892\n",
      "46m 47s (- 45m 33s) (38000 50%) 1.1431\n",
      "47m 24s (- 44m 56s) (38500 51%) 1.1702\n",
      "48m 1s (- 44m 19s) (39000 52%) 1.1020\n",
      "48m 38s (- 43m 43s) (39500 52%) 1.1572\n",
      "49m 19s (- 43m 9s) (40000 53%) 1.0597\n",
      "50m 0s (- 42m 36s) (40500 54%) 1.1083\n",
      "50m 40s (- 42m 0s) (41000 54%) 1.0813\n",
      "51m 16s (- 41m 23s) (41500 55%) 1.0923\n",
      "51m 54s (- 40m 47s) (42000 56%) 1.0490\n",
      "52m 34s (- 40m 12s) (42500 56%) 1.1041\n",
      "53m 21s (- 39m 42s) (43000 57%) 1.0295\n",
      "54m 1s (- 39m 7s) (43500 57%) 1.0683\n",
      "54m 41s (- 38m 31s) (44000 58%) 1.0259\n",
      "55m 24s (- 37m 58s) (44500 59%) 0.9843\n",
      "56m 21s (- 37m 34s) (45000 60%) 1.0156\n",
      "57m 0s (- 36m 57s) (45500 60%) 0.9908\n",
      "57m 36s (- 36m 19s) (46000 61%) 0.9556\n",
      "58m 15s (- 35m 42s) (46500 62%) 0.9834\n",
      "58m 53s (- 35m 5s) (47000 62%) 0.9917\n",
      "59m 33s (- 34m 28s) (47500 63%) 0.9153\n",
      "60m 7s (- 33m 49s) (48000 64%) 0.9578\n",
      "60m 41s (- 33m 9s) (48500 64%) 0.9620\n",
      "61m 17s (- 32m 31s) (49000 65%) 0.8647\n",
      "62m 2s (- 31m 57s) (49500 66%) 0.9322\n",
      "62m 43s (- 31m 21s) (50000 66%) 0.9342\n",
      "63m 19s (- 30m 43s) (50500 67%) 0.8177\n",
      "63m 56s (- 30m 5s) (51000 68%) 0.8989\n",
      "64m 35s (- 29m 28s) (51500 68%) 0.9554\n",
      "65m 16s (- 28m 52s) (52000 69%) 0.8749\n",
      "65m 55s (- 28m 15s) (52500 70%) 0.7855\n",
      "66m 34s (- 27m 38s) (53000 70%) 0.8484\n",
      "67m 11s (- 26m 59s) (53500 71%) 0.8633\n",
      "67m 45s (- 26m 21s) (54000 72%) 0.8245\n",
      "68m 20s (- 25m 42s) (54500 72%) 0.8853\n",
      "68m 57s (- 25m 4s) (55000 73%) 0.7897\n",
      "69m 37s (- 24m 27s) (55500 74%) 0.8275\n",
      "70m 16s (- 23m 50s) (56000 74%) 0.8294\n",
      "70m 55s (- 23m 13s) (56500 75%) 0.8753\n",
      "71m 33s (- 22m 35s) (57000 76%) 0.7700\n",
      "72m 12s (- 21m 58s) (57500 76%) 0.7318\n",
      "72m 51s (- 21m 21s) (58000 77%) 0.7734\n",
      "73m 29s (- 20m 43s) (58500 78%) 0.7645\n",
      "74m 9s (- 20m 6s) (59000 78%) 0.7684\n",
      "74m 48s (- 19m 29s) (59500 79%) 0.7606\n",
      "75m 29s (- 18m 52s) (60000 80%) 0.6869\n",
      "76m 8s (- 18m 14s) (60500 80%) 0.7283\n",
      "76m 47s (- 17m 37s) (61000 81%) 0.7322\n",
      "77m 27s (- 17m 0s) (61500 82%) 0.7174\n",
      "78m 9s (- 16m 23s) (62000 82%) 0.7342\n",
      "78m 52s (- 15m 46s) (62500 83%) 0.7700\n",
      "79m 32s (- 15m 9s) (63000 84%) 0.7191\n",
      "80m 11s (- 14m 31s) (63500 84%) 0.7536\n",
      "80m 51s (- 13m 53s) (64000 85%) 0.6816\n",
      "81m 32s (- 13m 16s) (64500 86%) 0.6179\n",
      "82m 13s (- 12m 38s) (65000 86%) 0.6635\n",
      "82m 56s (- 12m 1s) (65500 87%) 0.6249\n",
      "83m 37s (- 11m 24s) (66000 88%) 0.6539\n",
      "84m 20s (- 10m 46s) (66500 88%) 0.6493\n",
      "85m 2s (- 10m 9s) (67000 89%) 0.6835\n",
      "85m 43s (- 9m 31s) (67500 90%) 0.7251\n",
      "86m 24s (- 8m 53s) (68000 90%) 0.6508\n",
      "87m 5s (- 8m 15s) (68500 91%) 0.6791\n",
      "87m 46s (- 7m 37s) (69000 92%) 0.6024\n",
      "88m 28s (- 7m 0s) (69500 92%) 0.5718\n",
      "89m 10s (- 6m 22s) (70000 93%) 0.6152\n",
      "89m 52s (- 5m 44s) (70500 94%) 0.6618\n",
      "90m 33s (- 5m 6s) (71000 94%) 0.5858\n",
      "91m 15s (- 4m 28s) (71500 95%) 0.6396\n",
      "92m 1s (- 3m 50s) (72000 96%) 0.6381\n",
      "92m 45s (- 3m 11s) (72500 96%) 0.6357\n",
      "93m 29s (- 2m 33s) (73000 97%) 0.5963\n",
      "94m 10s (- 1m 55s) (73500 98%) 0.6224\n",
      "94m 53s (- 1m 16s) (74000 98%) 0.6277\n",
      "95m 34s (- 0m 38s) (74500 99%) 0.5280\n",
      "96m 9s (- 0m 0s) (75000 100%) 0.5161\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je suis desolee .\n",
      "= i m sorry .\n",
      "< i m sorry . <EOS>\n",
      "\n",
      "> il est encore fache .\n",
      "= he is still angry .\n",
      "< he is still angry . <EOS>\n",
      "\n",
      "> ce n est pas un menteur .\n",
      "= he s not a liar .\n",
      "< he s no liar . <EOS>\n",
      "\n",
      "> je suis methodique .\n",
      "= i m methodical .\n",
      "< i m a . <EOS>\n",
      "\n",
      "> c est maree basse .\n",
      "= you re out of booze .\n",
      "< you re out of booze . <EOS>\n",
      "\n",
      "> je suis un homme .\n",
      "= i m a man .\n",
      "< i am a man . <EOS>\n",
      "\n",
      "> il parle couramment le japonais .\n",
      "= he s fluent in japanese .\n",
      "< he s fluent in japanese . <EOS>\n",
      "\n",
      "> vous etes idiote .\n",
      "= you re silly .\n",
      "< you re silly . <EOS>\n",
      "\n",
      "> il est en train de pleurer .\n",
      "= he s crying .\n",
      "< he s crying . <EOS>\n",
      "\n",
      "> nous nous dirigeons vers le nord .\n",
      "= we re going north .\n",
      "< we re going to . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
