{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "[u'je ne suis pas la patronne .', u'i m not the boss .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 26s (- 66m 26s) (50 0%) 5.5387\n",
      "1m 7s (- 83m 30s) (100 1%) 3.7229\n",
      "1m 24s (- 68m 43s) (150 2%) 3.5902\n",
      "1m 43s (- 63m 15s) (200 2%) 3.5714\n",
      "1m 50s (- 53m 36s) (250 3%) 3.5438\n",
      "1m 56s (- 46m 40s) (300 4%) 3.3502\n",
      "2m 7s (- 43m 31s) (350 4%) 3.4810\n",
      "2m 22s (- 42m 17s) (400 5%) 3.7296\n",
      "2m 31s (- 39m 41s) (450 6%) 3.4619\n",
      "2m 38s (- 37m 5s) (500 6%) 3.5255\n",
      "2m 49s (- 35m 41s) (550 7%) 3.4069\n",
      "2m 55s (- 33m 39s) (600 8%) 3.1356\n",
      "3m 6s (- 32m 48s) (650 8%) 3.2805\n",
      "3m 14s (- 31m 29s) (700 9%) 3.3689\n",
      "3m 22s (- 30m 19s) (750 10%) 3.0328\n",
      "3m 32s (- 29m 40s) (800 10%) 3.2467\n",
      "3m 40s (- 28m 44s) (850 11%) 3.0939\n",
      "3m 48s (- 27m 55s) (900 12%) 3.0291\n",
      "4m 0s (- 27m 36s) (950 12%) 3.2841\n",
      "4m 5s (- 26m 36s) (1000 13%) 3.1471\n",
      "4m 15s (- 26m 9s) (1050 14%) 3.0888\n",
      "4m 22s (- 25m 28s) (1100 14%) 3.0182\n",
      "4m 33s (- 25m 10s) (1150 15%) 3.0361\n",
      "4m 43s (- 24m 46s) (1200 16%) 3.0572\n",
      "4m 51s (- 24m 19s) (1250 16%) 3.2207\n",
      "5m 5s (- 24m 17s) (1300 17%) 2.7688\n",
      "5m 14s (- 23m 51s) (1350 18%) 2.9760\n",
      "5m 23s (- 23m 27s) (1400 18%) 2.8503\n",
      "5m 42s (- 23m 49s) (1450 19%) 2.8219\n",
      "5m 51s (- 23m 24s) (1500 20%) 2.8329\n",
      "5m 58s (- 22m 56s) (1550 20%) 2.9941\n",
      "6m 8s (- 22m 37s) (1600 21%) 2.8750\n",
      "6m 14s (- 22m 8s) (1650 22%) 2.8797\n",
      "6m 26s (- 21m 59s) (1700 22%) 2.8510\n",
      "6m 32s (- 21m 30s) (1750 23%) 2.8008\n",
      "6m 40s (- 21m 8s) (1800 24%) 2.7424\n",
      "6m 47s (- 20m 44s) (1850 24%) 2.7757\n",
      "6m 55s (- 20m 23s) (1900 25%) 2.8138\n",
      "7m 7s (- 20m 17s) (1950 26%) 2.4941\n",
      "7m 15s (- 19m 57s) (2000 26%) 2.6899\n",
      "7m 25s (- 19m 44s) (2050 27%) 3.0053\n",
      "7m 49s (- 20m 7s) (2100 28%) 2.7670\n",
      "8m 5s (- 20m 9s) (2150 28%) 2.8820\n",
      "8m 16s (- 19m 57s) (2200 29%) 3.0303\n",
      "8m 23s (- 19m 34s) (2250 30%) 2.5503\n",
      "8m 32s (- 19m 19s) (2300 30%) 2.7132\n",
      "8m 39s (- 18m 57s) (2350 31%) 2.7475\n",
      "8m 48s (- 18m 43s) (2400 32%) 2.9182\n",
      "8m 54s (- 18m 21s) (2450 32%) 2.7966\n",
      "9m 1s (- 18m 3s) (2500 33%) 2.8382\n",
      "9m 7s (- 17m 43s) (2550 34%) 2.7345\n",
      "9m 15s (- 17m 27s) (2600 34%) 2.7847\n",
      "9m 23s (- 17m 10s) (2650 35%) 2.7372\n",
      "9m 31s (- 16m 56s) (2700 36%) 3.0279\n",
      "9m 37s (- 16m 37s) (2750 36%) 2.8628\n",
      "9m 46s (- 16m 24s) (2800 37%) 2.6496\n",
      "9m 52s (- 16m 7s) (2850 38%) 2.6505\n",
      "10m 1s (- 15m 53s) (2900 38%) 2.7766\n",
      "10m 10s (- 15m 40s) (2950 39%) 2.8050\n",
      "10m 15s (- 15m 23s) (3000 40%) 2.6716\n",
      "10m 24s (- 15m 10s) (3050 40%) 2.9125\n",
      "10m 31s (- 14m 56s) (3100 41%) 2.6046\n",
      "10m 37s (- 14m 40s) (3150 42%) 2.7097\n",
      "10m 45s (- 14m 27s) (3200 42%) 2.6510\n",
      "10m 54s (- 14m 15s) (3250 43%) 2.8961\n",
      "11m 6s (- 14m 8s) (3300 44%) 2.6039\n",
      "11m 14s (- 13m 55s) (3350 44%) 2.7122\n",
      "11m 21s (- 13m 41s) (3400 45%) 2.3787\n",
      "11m 33s (- 13m 34s) (3450 46%) 2.6809\n",
      "11m 39s (- 13m 19s) (3500 46%) 2.7209\n",
      "11m 45s (- 13m 4s) (3550 47%) 2.5485\n",
      "11m 55s (- 12m 55s) (3600 48%) 2.6602\n",
      "12m 3s (- 12m 42s) (3650 48%) 2.7515\n",
      "12m 11s (- 12m 31s) (3700 49%) 2.6350\n",
      "12m 19s (- 12m 19s) (3750 50%) 2.5091\n",
      "12m 36s (- 12m 16s) (3800 50%) 2.6828\n",
      "12m 41s (- 12m 2s) (3850 51%) 2.7088\n",
      "12m 47s (- 11m 48s) (3900 52%) 2.6231\n",
      "12m 54s (- 11m 35s) (3950 52%) 2.6992\n",
      "13m 0s (- 11m 23s) (4000 53%) 2.7329\n",
      "13m 5s (- 11m 9s) (4050 54%) 2.4203\n",
      "13m 11s (- 10m 56s) (4100 54%) 2.6463\n",
      "13m 20s (- 10m 46s) (4150 55%) 2.6140\n",
      "13m 25s (- 10m 33s) (4200 56%) 2.7502\n",
      "13m 32s (- 10m 21s) (4250 56%) 2.5726\n",
      "13m 37s (- 10m 8s) (4300 57%) 2.6526\n",
      "13m 43s (- 9m 56s) (4350 57%) 2.6731\n",
      "13m 49s (- 9m 44s) (4400 58%) 2.5194\n",
      "13m 54s (- 9m 32s) (4450 59%) 2.6865\n",
      "14m 0s (- 9m 20s) (4500 60%) 2.6551\n",
      "14m 6s (- 9m 9s) (4550 60%) 2.5913\n",
      "14m 11s (- 8m 56s) (4600 61%) 2.3420\n",
      "14m 17s (- 8m 45s) (4650 62%) 2.4620\n",
      "14m 23s (- 8m 34s) (4700 62%) 2.3765\n",
      "14m 29s (- 8m 23s) (4750 63%) 2.4390\n",
      "14m 35s (- 8m 12s) (4800 64%) 2.7032\n",
      "14m 42s (- 8m 2s) (4850 64%) 2.5689\n",
      "14m 47s (- 7m 51s) (4900 65%) 2.9176\n",
      "14m 54s (- 7m 40s) (4950 66%) 2.6252\n",
      "14m 59s (- 7m 29s) (5000 66%) 2.5878\n",
      "15m 5s (- 7m 19s) (5050 67%) 2.3342\n",
      "15m 13s (- 7m 9s) (5100 68%) 2.3900\n",
      "15m 18s (- 6m 59s) (5150 68%) 2.3940\n",
      "15m 23s (- 6m 48s) (5200 69%) 2.6710\n",
      "15m 29s (- 6m 38s) (5250 70%) 2.4481\n",
      "15m 37s (- 6m 29s) (5300 70%) 2.3930\n",
      "15m 42s (- 6m 18s) (5350 71%) 2.6518\n",
      "15m 49s (- 6m 9s) (5400 72%) 2.4190\n",
      "15m 54s (- 5m 59s) (5450 72%) 2.3171\n",
      "16m 1s (- 5m 49s) (5500 73%) 2.6221\n",
      "16m 7s (- 5m 39s) (5550 74%) 2.5395\n",
      "16m 12s (- 5m 30s) (5600 74%) 2.4213\n",
      "16m 19s (- 5m 20s) (5650 75%) 2.3850\n",
      "16m 24s (- 5m 11s) (5700 76%) 2.6269\n",
      "16m 29s (- 5m 1s) (5750 76%) 2.1930\n",
      "16m 35s (- 4m 51s) (5800 77%) 2.2993\n",
      "16m 41s (- 4m 42s) (5850 78%) 2.2608\n",
      "16m 48s (- 4m 33s) (5900 78%) 2.4657\n",
      "16m 54s (- 4m 24s) (5950 79%) 2.3178\n",
      "17m 2s (- 4m 15s) (6000 80%) 2.3828\n",
      "17m 15s (- 4m 8s) (6050 80%) 2.4272\n",
      "17m 28s (- 4m 0s) (6100 81%) 2.4004\n",
      "17m 36s (- 3m 51s) (6150 82%) 2.3543\n",
      "17m 41s (- 3m 42s) (6200 82%) 2.5286\n",
      "17m 49s (- 3m 33s) (6250 83%) 2.6712\n",
      "17m 54s (- 3m 24s) (6300 84%) 2.4507\n",
      "18m 2s (- 3m 15s) (6350 84%) 2.5407\n",
      "18m 7s (- 3m 6s) (6400 85%) 2.4827\n",
      "18m 15s (- 2m 58s) (6450 86%) 2.4042\n",
      "18m 20s (- 2m 49s) (6500 86%) 2.4788\n",
      "18m 27s (- 2m 40s) (6550 87%) 2.5526\n",
      "18m 33s (- 2m 31s) (6600 88%) 2.2747\n",
      "18m 41s (- 2m 23s) (6650 88%) 2.3889\n",
      "18m 47s (- 2m 14s) (6700 89%) 2.4147\n",
      "18m 52s (- 2m 5s) (6750 90%) 2.5042\n",
      "18m 58s (- 1m 57s) (6800 90%) 2.1837\n",
      "19m 4s (- 1m 48s) (6850 91%) 2.2690\n",
      "19m 10s (- 1m 40s) (6900 92%) 2.6065\n",
      "19m 17s (- 1m 31s) (6950 92%) 2.6155\n",
      "19m 23s (- 1m 23s) (7000 93%) 2.4640\n",
      "19m 29s (- 1m 14s) (7050 94%) 2.0832\n",
      "19m 37s (- 1m 6s) (7100 94%) 2.1495\n",
      "19m 42s (- 0m 57s) (7150 95%) 2.4343\n",
      "19m 49s (- 0m 49s) (7200 96%) 2.6295\n",
      "19m 56s (- 0m 41s) (7250 96%) 2.4921\n",
      "20m 2s (- 0m 32s) (7300 97%) 2.5151\n",
      "20m 11s (- 0m 24s) (7350 98%) 2.3729\n",
      "20m 16s (- 0m 16s) (7400 98%) 2.5540\n",
      "20m 22s (- 0m 8s) (7450 99%) 2.4857\n",
      "20m 30s (- 0m 0s) (7500 100%) 2.2228\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> il est professeur et romancier .\n",
      "= he is a teacher and novelist .\n",
      "< he is a of . . <EOS>\n",
      "\n",
      "> nous fermons tot .\n",
      "= we re closing early .\n",
      "< we re looking . <EOS>\n",
      "\n",
      "> il est tout sauf mort .\n",
      "= he is all but dead .\n",
      "< he is always of . . <EOS>\n",
      "\n",
      "> tu es le seul pour moi maintenant .\n",
      "= you re the only one for me now .\n",
      "< you re the to me . <EOS>\n",
      "\n",
      "> je me fais trop vieux pour ce travail .\n",
      "= i m getting too old for this job .\n",
      "< i m too old for you . <EOS>\n",
      "\n",
      "> c est un malade du controle .\n",
      "= he s a control freak .\n",
      "< he is a bit . . <EOS>\n",
      "\n",
      "> vous etes tres attirantes .\n",
      "= you re very attractive .\n",
      "< you re very timid . <EOS>\n",
      "\n",
      "> tu es le meilleur pour ce travail .\n",
      "= you re the best man for the job .\n",
      "< you re the to me . <EOS>\n",
      "\n",
      "> vous etes aveugle par l amour .\n",
      "= you are blinded by love .\n",
      "< you re the one of . <EOS>\n",
      "\n",
      "> vous etes plantee .\n",
      "= you re stuck .\n",
      "< you re the . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
