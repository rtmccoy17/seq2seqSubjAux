{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code is a modified version of the seq2seq code found at\n",
    "# the following tutorial:\n",
    "# http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "# Imports. \n",
    "# Note that you must have PyTorch installed before you can run this.\n",
    "# You can get PyTorch here: http://pytorch.org/\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# I ran this without cuda. Cuda allows you to use a GPU, so\n",
    "# we'll probably want to use it for more complex experiments\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start-of-sentence and end-of-sentence tokens\n",
    "# The standard seq2seq version only has one EOS. This version has \n",
    "# 2 EOS--one signalling that the original sentence should be returned,\n",
    "# the other signalling it should be reversed.\n",
    "# I use a 1-hot encoding for all tokens.\n",
    "SOS_token = 0\n",
    "EOS_tokenA = 1 # For FWD\n",
    "EOS_tokenB = 2 # For REV\n",
    "\n",
    "# Defining the encodings for each token\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {u\"fwd\": 1, u\"rev\": 2}\n",
    "        self.word2count = {u\"fwd\": 0, u\"rev\": 0}\n",
    "        self.index2word = {0: \"SOS\", 1: \"fwd\", 2: \"rev\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# String processing stuff\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the training data\n",
    "\n",
    "trainingFile = 'abcd.train'\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(trainingFile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Max sentence length\n",
    "# Not applicable here, since all sentences are at most 8 long.\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 144000 sentence pairs\n",
      "Trimmed to 144000 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 7\n",
      "fra 7\n",
      "[u'd b a a rev', u'a a b d rev']\n"
     ]
    }
   ],
   "source": [
    "# Preparing data--also not really applicable here because we've already\n",
    "# restricted the lengths of our training data. (This does lowercase the\n",
    "# input and remove punctuation, but those things also don't matter here)\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class for the encoder RNN\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    # For succesively generating each new output and hidden layer\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    # Creates the initial hidden state\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class for the basic decoder RNN, without attention\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    # For successively generating each new output and hidden layer\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    # Creates the initial hidden state\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class for a decoder RNN using attention\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    # For successively generating each new output and hidden layer\n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    # Creates the initial hidden state\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Methods for interfacing between words and one-hot encodings\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    #indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This affects how training proceeds. I've run it with the default value\n",
    "# of 0.5 but am trying it with 0.0 now.\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "# Training the seq2seq network\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            if ni == EOS_tokenA or ni == EOS_tokenB:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions for tracking time\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training iterations\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for graphically displaying results\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate a single sentence\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_tokenA:\n",
    "            decoded_words.append('FWD')\n",
    "            break\n",
    "        elif ni == EOS_tokenB:\n",
    "            decoded_words.append('REV')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the output for a few randomly selected sentences\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 20s (- 41m 28s) (1000 0%) 1.2079\n",
      "0m 42s (- 42m 5s) (2000 1%) 0.6930\n",
      "3m 25s (- 133m 22s) (3000 2%) 0.5319\n",
      "3m 46s (- 109m 20s) (4000 3%) 0.4514\n",
      "4m 5s (- 94m 14s) (5000 4%) 0.3851\n",
      "4m 23s (- 83m 29s) (6000 5%) 0.2976\n",
      "4m 41s (- 75m 46s) (7000 5%) 0.2830\n",
      "4m 59s (- 69m 50s) (8000 6%) 0.2226\n",
      "5m 20s (- 65m 50s) (9000 7%) 0.2120\n",
      "5m 39s (- 62m 16s) (10000 8%) 0.1792\n",
      "5m 58s (- 59m 9s) (11000 9%) 0.1204\n",
      "6m 16s (- 56m 28s) (12000 10%) 0.1396\n",
      "6m 33s (- 54m 2s) (13000 10%) 0.0955\n",
      "6m 52s (- 52m 4s) (14000 11%) 0.0804\n",
      "7m 12s (- 50m 27s) (15000 12%) 0.1573\n",
      "7m 31s (- 48m 52s) (16000 13%) 0.0774\n",
      "7m 49s (- 47m 23s) (17000 14%) 0.0926\n",
      "8m 8s (- 46m 6s) (18000 15%) 0.0947\n",
      "8m 26s (- 44m 50s) (19000 15%) 0.0955\n",
      "8m 44s (- 43m 43s) (20000 16%) 0.0696\n",
      "9m 3s (- 42m 40s) (21000 17%) 0.0828\n",
      "9m 21s (- 41m 41s) (22000 18%) 0.0911\n",
      "9m 40s (- 40m 48s) (23000 19%) 0.1024\n",
      "9m 59s (- 39m 58s) (24000 20%) 0.1103\n",
      "10m 18s (- 39m 10s) (25000 20%) 0.0569\n",
      "10m 37s (- 38m 25s) (26000 21%) 0.0525\n",
      "10m 57s (- 37m 43s) (27000 22%) 0.0615\n",
      "11m 15s (- 37m 0s) (28000 23%) 0.0972\n",
      "11m 34s (- 36m 19s) (29000 24%) 0.0684\n",
      "11m 52s (- 35m 38s) (30000 25%) 0.0413\n",
      "12m 11s (- 35m 0s) (31000 25%) 0.0701\n",
      "12m 30s (- 34m 24s) (32000 26%) 0.0552\n",
      "12m 49s (- 33m 49s) (33000 27%) 0.0344\n",
      "13m 8s (- 33m 14s) (34000 28%) 0.0645\n",
      "13m 27s (- 32m 40s) (35000 29%) 0.0511\n",
      "13m 46s (- 32m 8s) (36000 30%) 0.0588\n",
      "14m 4s (- 31m 34s) (37000 30%) 0.0440\n",
      "14m 22s (- 31m 1s) (38000 31%) 0.0327\n",
      "14m 42s (- 30m 32s) (39000 32%) 0.0248\n",
      "15m 1s (- 30m 2s) (40000 33%) 0.0560\n",
      "15m 20s (- 29m 33s) (41000 34%) 0.0357\n",
      "15m 39s (- 29m 5s) (42000 35%) 0.0246\n",
      "15m 59s (- 28m 38s) (43000 35%) 0.0924\n",
      "16m 19s (- 28m 11s) (44000 36%) 0.0688\n",
      "16m 38s (- 27m 44s) (45000 37%) 0.0423\n",
      "16m 58s (- 27m 18s) (46000 38%) 0.0401\n",
      "17m 18s (- 26m 52s) (47000 39%) 0.0510\n",
      "17m 37s (- 26m 25s) (48000 40%) 0.0182\n",
      "17m 56s (- 26m 0s) (49000 40%) 0.0525\n",
      "18m 15s (- 25m 34s) (50000 41%) 0.0414\n",
      "18m 34s (- 25m 7s) (51000 42%) 0.0497\n",
      "18m 54s (- 24m 43s) (52000 43%) 0.0326\n",
      "19m 13s (- 24m 17s) (53000 44%) 0.0301\n",
      "19m 32s (- 23m 53s) (54000 45%) 0.0190\n",
      "19m 51s (- 23m 28s) (55000 45%) 0.0792\n",
      "20m 10s (- 23m 3s) (56000 46%) 0.0977\n",
      "22m 17s (- 24m 37s) (57000 47%) 0.0356\n",
      "22m 37s (- 24m 11s) (58000 48%) 0.0419\n",
      "22m 56s (- 23m 43s) (59000 49%) 0.0215\n",
      "23m 16s (- 23m 16s) (60000 50%) 0.0145\n",
      "23m 36s (- 22m 49s) (61000 50%) 0.0148\n",
      "23m 55s (- 22m 22s) (62000 51%) 0.0472\n",
      "24m 15s (- 21m 56s) (63000 52%) 0.0227\n",
      "24m 35s (- 21m 30s) (64000 53%) 0.0213\n",
      "24m 53s (- 21m 3s) (65000 54%) 0.0476\n",
      "25m 11s (- 20m 36s) (66000 55%) 0.0992\n",
      "25m 29s (- 20m 9s) (67000 55%) 0.0867\n",
      "25m 47s (- 19m 43s) (68000 56%) 0.0658\n",
      "26m 5s (- 19m 17s) (69000 57%) 0.0516\n",
      "26m 23s (- 18m 50s) (70000 58%) 0.0366\n",
      "26m 41s (- 18m 25s) (71000 59%) 0.0217\n",
      "26m 59s (- 17m 59s) (72000 60%) 0.0238\n",
      "27m 17s (- 17m 34s) (73000 60%) 0.0190\n",
      "27m 35s (- 17m 8s) (74000 61%) 0.1667\n",
      "27m 53s (- 16m 43s) (75000 62%) 0.1778\n",
      "28m 10s (- 16m 18s) (76000 63%) 0.1256\n",
      "28m 28s (- 15m 54s) (77000 64%) 0.0677\n",
      "28m 47s (- 15m 30s) (78000 65%) 0.2547\n",
      "29m 4s (- 15m 5s) (79000 65%) 0.5998\n",
      "29m 23s (- 14m 41s) (80000 66%) 0.4984\n",
      "29m 40s (- 14m 17s) (81000 67%) 0.2602\n",
      "30m 3s (- 13m 55s) (82000 68%) 0.2228\n",
      "30m 21s (- 13m 31s) (83000 69%) 0.1900\n",
      "30m 39s (- 13m 8s) (84000 70%) 0.1706\n",
      "30m 58s (- 12m 45s) (85000 70%) 0.2310\n",
      "31m 16s (- 12m 21s) (86000 71%) 0.1467\n",
      "31m 34s (- 11m 58s) (87000 72%) 0.1297\n",
      "31m 52s (- 11m 35s) (88000 73%) 0.0934\n",
      "32m 10s (- 11m 12s) (89000 74%) 0.0932\n",
      "32m 28s (- 10m 49s) (90000 75%) 0.1015\n",
      "32m 46s (- 10m 26s) (91000 75%) 0.1864\n",
      "33m 4s (- 10m 4s) (92000 76%) 0.0994\n",
      "33m 22s (- 9m 41s) (93000 77%) 0.0821\n",
      "33m 40s (- 9m 18s) (94000 78%) 0.1178\n",
      "33m 58s (- 8m 56s) (95000 79%) 0.1054\n",
      "34m 16s (- 8m 34s) (96000 80%) 0.0810\n",
      "34m 34s (- 8m 11s) (97000 80%) 0.0699\n",
      "34m 52s (- 7m 49s) (98000 81%) 0.1133\n",
      "35m 10s (- 7m 27s) (99000 82%) 1.0358\n",
      "35m 28s (- 7m 5s) (100000 83%) 0.8221\n",
      "35m 46s (- 6m 43s) (101000 84%) 0.7713\n",
      "36m 4s (- 6m 22s) (102000 85%) 0.6930\n",
      "36m 23s (- 6m 0s) (103000 85%) 0.7881\n",
      "36m 41s (- 5m 38s) (104000 86%) 0.8016\n",
      "36m 59s (- 5m 17s) (105000 87%) 0.7118\n",
      "37m 17s (- 4m 55s) (106000 88%) 0.7894\n",
      "37m 36s (- 4m 34s) (107000 89%) 0.7329\n",
      "37m 53s (- 4m 12s) (108000 90%) 0.7048\n",
      "38m 11s (- 3m 51s) (109000 90%) 0.6043\n",
      "38m 28s (- 3m 29s) (110000 91%) 0.5393\n",
      "40m 28s (- 3m 16s) (111000 92%) 0.5592\n",
      "40m 45s (- 2m 54s) (112000 93%) 0.5752\n",
      "41m 4s (- 2m 32s) (113000 94%) 0.5279\n",
      "41m 21s (- 2m 10s) (114000 95%) 0.5291\n",
      "41m 39s (- 1m 48s) (115000 95%) 0.5032\n",
      "41m 56s (- 1m 26s) (116000 96%) 0.4297\n",
      "42m 13s (- 1m 4s) (117000 97%) 0.4268\n",
      "42m 31s (- 0m 43s) (118000 98%) 0.4100\n",
      "42m 48s (- 0m 21s) (119000 99%) 0.4243\n",
      "43m 6s (- 0m 0s) (120000 100%) 0.3879\n"
     ]
    }
   ],
   "source": [
    "# Where the actual running of the code happens\n",
    "hidden_size = 100\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 120000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> d d b d a d c b fwd\n",
      "= d d b d a d c b fwd\n",
      "< d d b d a d c FWD\n",
      "\n",
      "> d b d c fwd\n",
      "= d b d c fwd\n",
      "< d b d c FWD\n",
      "\n",
      "> d b fwd\n",
      "= d b fwd\n",
      "< d b FWD\n",
      "\n",
      "> b d b c a rev\n",
      "= a c b d b rev\n",
      "< a c b d b REV\n",
      "\n",
      "> a rev\n",
      "= a rev\n",
      "< a REV\n",
      "\n",
      "> c d rev\n",
      "= d c rev\n",
      "< d c REV\n",
      "\n",
      "> c b c c c a fwd\n",
      "= c b c c c a fwd\n",
      "< c b c c c a FWD\n",
      "\n",
      "> a a a b b rev\n",
      "= b b a a a rev\n",
      "< b b a a a REV\n",
      "\n",
      "> a c b d a fwd\n",
      "= a c b d a fwd\n",
      "< a c b d a FWD\n",
      "\n",
      "> d fwd\n",
      "= d fwd\n",
      "< d FWD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 16, 23, 192, 210] [0, 16, 23, 231, 230] [0, 14, 21, 189, 142] [0, 16, 23, 231, 230]\n",
      "[0, 32, 56, 374, 429] [0, 32, 56, 444, 468] [0, 27, 47, 298, 225] [0, 32, 56, 444, 468]\n",
      "[0, 47, 98, 549, 650] [0, 47, 98, 648, 707] [0, 41, 81, 456, 372] [0, 47, 98, 648, 707]\n",
      "[0, 66, 131, 727, 861] [0, 66, 131, 864, 939] [0, 60, 114, 597, 477] [0, 66, 131, 864, 939]\n",
      "[0, 83, 150, 925, 1090] [0, 83, 150, 1083, 1184] [0, 75, 125, 743, 616] [0, 83, 150, 1083, 1184]\n",
      "[0, 101, 174, 1097, 1313] [0, 101, 174, 1300, 1425] [0, 88, 136, 855, 726] [0, 101, 174, 1300, 1425]\n",
      "[0, 116, 198, 1268, 1553] [0, 116, 198, 1505, 1681] [0, 101, 143, 953, 878] [0, 116, 198, 1505, 1681]\n",
      "[0, 134, 221, 1469, 1761] [0, 134, 221, 1732, 1913] [0, 119, 163, 1120, 1044] [0, 134, 221, 1732, 1913]\n",
      "[1, 153, 251, 1654, 1966] [1, 153, 251, 1956, 2139] [1, 138, 188, 1233, 1137] [1, 153, 251, 1956, 2139]\n",
      "[1, 170, 282, 1832, 2188] [1, 170, 282, 2163, 2384] [1, 155, 212, 1400, 1314] [1, 170, 282, 2163, 2384]\n",
      "[1, 187, 316, 2011, 2410] [1, 187, 316, 2373, 2623] [1, 172, 239, 1525, 1409] [1, 187, 316, 2373, 2623]\n",
      "[1, 206, 340, 2206, 2623] [1, 206, 340, 2591, 2862] [1, 190, 254, 1685, 1560] [1, 206, 340, 2591, 2862]\n",
      "[1, 222, 373, 2399, 2843] [1, 222, 373, 2793, 3111] [1, 206, 286, 1845, 1717] [1, 222, 373, 2793, 3111]\n",
      "[1, 237, 403, 2593, 3059] [1, 237, 403, 3006, 3353] [1, 221, 303, 1989, 1864] [1, 237, 403, 3006, 3353]\n",
      "[1, 254, 433, 2778, 3284] [1, 254, 433, 3222, 3590] [1, 236, 320, 2147, 2002] [1, 254, 433, 3222, 3590]\n",
      "[1, 274, 459, 2979, 3489] [1, 274, 459, 3451, 3815] [1, 254, 332, 2281, 2135] [1, 274, 459, 3451, 3815]\n",
      "[1, 294, 485, 3174, 3706] [1, 294, 486, 3660, 4059] [1, 274, 353, 2439, 2305] [1, 294, 486, 3660, 4059]\n",
      "[1, 310, 518, 3388, 3915] [1, 310, 519, 3882, 4288] [1, 290, 382, 2584, 2435] [1, 310, 519, 3882, 4288]\n",
      "[1, 327, 539, 3565, 4144] [1, 327, 540, 4087, 4545] [1, 303, 400, 2733, 2598] [1, 327, 540, 4087, 4545]\n",
      "[1, 344, 565, 3740, 4365] [1, 344, 566, 4304, 4785] [1, 317, 417, 2819, 2655] [1, 344, 566, 4304, 4785]\n",
      "[1, 362, 593, 3930, 4571] [1, 362, 594, 4529, 5014] [1, 332, 435, 2968, 2756] [1, 362, 594, 4529, 5014]\n",
      "[1, 377, 617, 4124, 4787] [1, 377, 618, 4755, 5249] [1, 347, 457, 3087, 2841] [1, 377, 618, 4755, 5249]\n",
      "[1, 393, 647, 4332, 4997] [1, 393, 648, 4985, 5473] [1, 359, 476, 3238, 2969] [1, 393, 648, 4985, 5473]\n",
      "[1, 409, 673, 4527, 5212] [1, 409, 674, 5206, 5710] [1, 371, 490, 3362, 3062] [1, 409, 674, 5206, 5710]\n",
      "[1, 422, 691, 4736, 5419] [1, 422, 692, 5445, 5940] [1, 381, 496, 3465, 3179] [1, 422, 692, 5445, 5940]\n",
      "[1, 438, 716, 4916, 5658] [1, 438, 717, 5648, 6196] [1, 392, 516, 3578, 3326] [1, 438, 717, 5648, 6196]\n",
      "[1, 454, 741, 5114, 5889] [1, 454, 742, 5861, 6442] [1, 401, 536, 3678, 3385] [1, 454, 742, 5861, 6442]\n",
      "[1, 472, 772, 5286, 6112] [1, 472, 773, 6074, 6680] [1, 415, 562, 3836, 3555] [1, 472, 773, 6074, 6680]\n",
      "[1, 495, 799, 5451, 6329] [1, 495, 800, 6285, 6919] [1, 432, 582, 3941, 3623] [1, 495, 800, 6285, 6919]\n",
      "[1, 515, 825, 5649, 6542] [1, 515, 826, 6504, 7154] [1, 450, 595, 4096, 3732] [1, 515, 826, 6504, 7154]\n",
      "[1, 528, 851, 5852, 6767] [1, 528, 852, 6719, 7400] [1, 462, 619, 4259, 3863] [1, 528, 852, 6719, 7400]\n",
      "[1, 547, 881, 6062, 6974] [1, 547, 882, 6946, 7624] [1, 480, 633, 4404, 3982] [1, 547, 882, 6946, 7624]\n",
      "[1, 562, 910, 6263, 7197] [1, 562, 911, 7165, 7861] [1, 489, 649, 4520, 4108] [1, 562, 911, 7165, 7861]\n",
      "[1, 573, 936, 6452, 7421] [1, 573, 937, 7387, 8102] [1, 497, 659, 4657, 4253] [1, 573, 937, 7387, 8102]\n",
      "[1, 587, 968, 6669, 7626] [1, 587, 969, 7611, 8332] [1, 511, 680, 4817, 4401] [1, 587, 969, 7611, 8332]\n",
      "[1, 603, 995, 6879, 7840] [1, 603, 996, 7834, 8566] [1, 527, 702, 4958, 4527] [1, 603, 996, 7834, 8566]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "testSet = open(\"abcd.test\", \"r\")\n",
    "testSents = testSet.readlines()\n",
    "\n",
    "# Keeping track of number correct per input length\n",
    "# Index 1 corresponds to length 4, index 2 to length 5, etc.\n",
    "correctfwd = [0,0,0,0,0]\n",
    "correctrev = [0,0,0,0,0]\n",
    "totalfwd = [0,0,0,0,0]\n",
    "totalrev = [0,0,0,0,0]\n",
    "\n",
    "count = 0\n",
    "\n",
    "for sentenceInit in testSents:\n",
    "    sentence = sentenceInit.split(\"\\t\")[0].lower()\n",
    "    output = sentenceInit.split(\"\\t\")[1].lower().strip()\n",
    "    result, att = (evaluate(encoder1, attn_decoder1, sentence))\n",
    "    correct = output == \" \".join(result).lower()\n",
    "    \n",
    "    length = len(sentence.split()) - 1\n",
    "    if sentence[-3:] == \"fwd\":\n",
    "        #correct = sentence == \" \".join(result).lower()\n",
    "        correctfwd[length - 4] += correct\n",
    "        totalfwd[length - 4] += 1\n",
    "    else:\n",
    "        correctrev[length - 4] += correct\n",
    "        totalrev[length - 4] += 1\n",
    "    \n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(correctfwd, totalfwd, correctrev, totalrev)\n",
    "    #print(sentence, \" \".join(result).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a c a c d fwd a c a c d c fwd False False\n",
      "a c a c d rev d c a rev False False\n",
      "a c a c d a a b fwd a c a d b c a fwd False False\n",
      "a c a c d a a b rev b a a c d c a rev False False\n",
      "a c a c d a b fwd a c a d b c a fwd False False\n",
      "a c a c d a b rev b a d c c a rev False False\n",
      "a c a c d a b a fwd a c a d b c a fwd False False\n",
      "a c a c d a b a rev a b a d c c a rev False False\n",
      "a c a c d a c fwd a c a d c a c fwd False False\n",
      "a c a c d a c rev c a d c a rev False False\n",
      "a c a c d a c b fwd a c a d b c fwd False False\n",
      "a c a c d a c b rev c b a c d c a rev False False\n",
      "a c a c d a c d fwd a c a d c a d c d c False False\n",
      "a c a c d a c d rev d c a d c d rev False False\n",
      "a c a c d a d c fwd a c a d c d c d c d False False\n",
      "a c a c d a d c rev c d a d c d rev False False\n",
      "a c a c d b b fwd a c b b d c a c fwd False False\n",
      "a c a c d b b rev b b d c c a rev False False\n",
      "a c a c d c a fwd a c a d c a c c fwd False False\n",
      "a c a c d c a rev a c d c a rev False False\n"
     ]
    }
   ],
   "source": [
    "# You can use this cell to look at some specific examples of the output\n",
    "for sentenceInit in testSents[5000:5020]:\n",
    "    sentence = sentenceInit.split(\"\\t\")[0].lower()\n",
    "    result, att = (evaluate(encoder1, attn_decoder1, sentence))\n",
    "    correct = sentence == \" \".join(result).lower()\n",
    "    \n",
    "    length = len(sentence.split()) - 1\n",
    "    if sentence[-3:] == \"fwd\":\n",
    "        correctfwd[length - 4] += correct\n",
    "        totalfwd[length - 4] += 1\n",
    "    else:\n",
    "        correctrev[length - 4] += correct\n",
    "        totalrev[length - 4] += 1\n",
    "    \n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(correctfwd, totalfwd, correctrev, totalrev)\n",
    "    print(sentence, \" \".join(result).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
